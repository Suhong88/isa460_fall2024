{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7766864e-a302-4cd4-9d05-55f6a0fd01b9",
   "metadata": {},
   "source": [
    "# Chapter 4 Analyzing tabular data with pyspark\n",
    "\n",
    "This chapter cover:\n",
    "\n",
    "- Reading delimited data into a PySpark data frame\n",
    "- Understanding how PySpark represents tabular data in a data frame\n",
    "- Ingesting and exploring tabular or relational data\n",
    "- Selecting, manipulating, renaming, and deleting columns in a data frame\n",
    "- Summarizing data frames for quick exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2d7c37-7db4-4dc3-aba9-23dea7e68d7c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "# change the account name to your email account\n",
    "account='sli'\n",
    "\n",
    "# define a root path to access the data in the DataAnalysisWithPythonAndPySpark\n",
    "data_path='/net/clusterhn/home/'+account+'/isa460/data/'\n",
    "\n",
    "# create a spark session\n",
    "spark = (SparkSession.builder.appName(\"Analyzing tabluar data\")\n",
    "        .config(\"spark.port.maxRetries\", \"100\")\n",
    "        .getOrCreate())\n",
    "\n",
    "# confiture the log level (defaulty is WWARN)\n",
    "spark.sparkContext.setLogLevel('ERROR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4cca5c-fe22-480c-9e06-f491d35d13c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import data from a list of lists\n",
    "\n",
    "my_grocery_list=[\n",
    "    [\"Banana\", 2, 1.74],\n",
    "    [\"Apple\", 4, 2.04],\n",
    "    [\"Carrot\", 1, 1.09],\n",
    "    [\"cake\", 1, 10.99]\n",
    "]\n",
    "\n",
    "# create a Dataframe based on the list\n",
    "\n",
    "df=spark.createDataFrame(my_grocery_list, [\"Item\", \"Quantity\", \"Price\"])\n",
    "\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe242b3-12e7-453e-a4f2-0c8718a6c23d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## import data from a csv file\n",
    "\n",
    "For this exercise, we’ll use some open data from the government of Canada, more specifically the CRTC (Canadian Radio-Television and Telecommunications Commission). Every broadcaster is mandated to provide a complete log of the programs and commercials showcased to the Canadian public. This gives us a lot of potential questions to answer, but we’ll select just one:\n",
    "**What are the channels with the greatest and least proportion of commercials?**\n",
    "\n",
    "You can download the [file](http://mng.bz/y4YJ) on the Canada Open Data portal ; select the BroadcastLogs_2018_Q3_M8 file. The file is 994 MB to download, which might be too large, depending on your computer. The book’s repository contains a sample of the data under the data/broadcast_logs directory, which you can use in place of the original file. You also need to download the Data Dictionary in .doc form, as well as the Reference Tables zip file, unzipping them into a ReferenceTables directory in data/ broadcast_logs. Once again, the examples assume that the data is downloaded under data/broadcast_logs and that PySpark is launched from the root of the repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db14242-421f-4469-adbb-4bc1e1a9edaf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "directory=data_path+'/broadcast_logs/'\n",
    "\n",
    "logs=spark.read.csv(os.path.join(directory, \"BroadcastLogs_2018_Q3_M8_sample.CSV\"),\n",
    "                                 sep=\"|\",\n",
    "                                 header=True,\n",
    "                                 inferSchema=True,\n",
    "                                 timestampFormat=\"yyyy-MM-dd\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c2fd48-837b-416e-a91c-d7a43de6ca8b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "logs.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c50b891d-dad2-4ee3-8166-f76738859501",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Exploring the shape of our data universe\n",
    "\n",
    "![Figure 4.4](https://raw.githubusercontent.com/Suhong88/ISA460_Fall2023/main/images/Figure%204.4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774fc22f-2188-445e-b942-70134370abb2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## The basics of data manipulation: Selecting, dropping, renaming, ordering, diagnosing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08167597-7be7-4ec6-8e26-1d4f72049600",
   "metadata": {},
   "source": [
    "### Select columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6b3968-4562-4480-834b-bad621eaf3a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54393b70-1fb5-44ed-bb6b-b92e41738f81",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# four ways of selecting columns\n",
    "# Using the string to column conversion\n",
    "logs.select(\"BroadCastLogID\", \"LogServiceID\", \"LogDate\")\n",
    "\n",
    "# use * to unpack a list\n",
    "logs.select(*[\"BroadCastLogID\", \"LogServiceID\", \"LogDate\"])\n",
    " \n",
    "# Passing the column object explicitly\n",
    "logs.select(\n",
    "    F.col(\"BroadCastLogID\"), F.col(\"LogServiceID\"), F.col(\"LogDate\")\n",
    ")\n",
    "logs.select(\n",
    "    *[F.col(\"BroadCastLogID\"), F.col(\"LogServiceID\"), F.col(\"LogDate\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f06e5d-ae55-4b20-8c08-2d18f0c630c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for a dataframe with a lot of columns, we can slice the columns into groups to display them by small groups\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d4ef3b-425e-4433-b69b-a9168439002b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "490c1736-c8da-4646-bbc5-ba833acd3429",
   "metadata": {},
   "source": [
    "### Drop columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60771f7-93f8-42a2-8c91-e7f519a52280",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447f5325-2b39-4904-9491-c4850f74892f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# instead drop, you can also select the ones you want to keep\n",
    "logs1 = logs.select(\n",
    "    *[x for x in logs.columns if x not in [\"BroadcastLogID\", \"SequenceNO\"]]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f198b5-d291-4ebe-9fe4-02f3190c8ae7",
   "metadata": {},
   "source": [
    "### Create new columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601c63f1-612b-4bc4-8f58-b59d23e6a818",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create a column showing duration in seconds\n",
    "\n",
    "logs.select(\"Duration\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e380b6-466c-4e94-9ad7-07aeefb78dee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "logs.select(F.col(\"Duration\")).dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180cd7db-7cf7-4f98-bdb6-5be9a2511ff2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# step 1: extract hours, minutes and seconds\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42fd5ddf-1715-4e4e-b36f-b6c5eb14cf93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# step 2. merge all fields into one\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd078607-df1c-4dc8-b69f-77eeb27eefd7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create a new column for duration in seconds\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f158a873-3eab-46ae-afbb-50df7fb90035",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print Schema. Why I do not see the new column?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6aa13d-3872-456b-876b-5fee93f4ff52",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b4474557-ecad-4d4a-9cc2-87f36dd27666",
   "metadata": {},
   "source": [
    "![Warning](https://raw.githubusercontent.com/Suhong88/ISA460_Fall2023/main/images/Figure%204.5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "634efaf1-1c8a-4d6d-9a40-8df15c47519b",
   "metadata": {},
   "source": [
    "### Rename and Reordering columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ba2fc0-0895-4ce9-ae73-3b189efa2bb0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79192791-87a3-4da4-9814-04d2f536c811",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# change all columns to lower case\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af1a0d7-6d48-4f64-b7ca-7b6c429a9021",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# order all columns in alphabetical order\n",
    "\n",
    "\n",
    "# store the result into a new dataframe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36377169-1c00-4313-8a24-6d01ed170906",
   "metadata": {},
   "source": [
    "### Diagnosing a data frame with describe() and summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6355bb40-31d8-4442-a4fa-9ae6101a9c76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#logs.describe().show()\n",
    "\n",
    "# for a dataframe with a lot of column, we can describe it one by one\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553a62f3-219e-40f1-afea-76318d952df6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# return numerical columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273caf61-f8af-461c-8ef1-26ab7a0077d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# apply describe to numerical columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27bec072-5d7f-46d9-bf87-d9b60b8772e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# apply summary to numerical columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db16d8a-0435-44b5-8075-0b4a481d663c",
   "metadata": {},
   "source": [
    "### In class Exercise: create a new data frame, logs_clean, that contains only the columns that do not end with ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9d3066-80b0-4fe4-88dc-ef3bc558e7e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "directory=data_path+'/broadcast_logs/'\n",
    "\n",
    "logs=spark.read.csv(os.path.join(directory, \"BroadcastLogs_2018_Q3_M8_sample.CSV\"),\n",
    "                                 sep=\"|\",\n",
    "                                 header=True,\n",
    "                                 inferSchema=True,\n",
    "                                 timestampFormat=\"yyyy-MM-dd\",)\n",
    "logs.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c79c25-e99f-41af-bc8b-45a94a071a27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d8446c68-ebea-4a45-bb2e-f3cfd4dba1b4",
   "metadata": {},
   "source": [
    "### Display a list of program title that includes word apple, remove duplidate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fbab012-e7ad-4d07-b004-48a2474cde63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "276fd140-2a31-45cf-94ad-7974f5193cee",
   "metadata": {},
   "source": [
    "### Display top 5 program title based on number of times it has been broadcasted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87525ab0-7134-4fe9-91b3-5e6113a0f4c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cdf26ff-99a1-4745-a39f-e4d615444465",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Big Data Analytics",
   "language": "python",
   "name": "bigdataanalytics"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
