{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71349ff1-3dd6-426e-bdca-3ded736ebb35",
   "metadata": {},
   "source": [
    "# Chapter 10 Your data under a different lens: Window functions\n",
    "we will disucss\n",
    "- Window functions and the kind of data transformation they enable\n",
    "- Summarizing, ranking, and analyzing data using the different classes of window functions\n",
    "- Building static, growing, and unbounded windows to your functions\n",
    "- Apply UDF to windows as custom window functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98dd82f1-09e6-4cc7-8654-463f9f295a54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.utils import AnalysisException\n",
    "import pyspark.sql.functions as F\n",
    "import pyspark.sql.types as T\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# change the account name to your email account\n",
    "account='sli'\n",
    "\n",
    "# define a root path to access the data in the DataAnalysisWithPythonAndPySpark\n",
    "data_path='/net/clusterhn/home/'+account+'/isa460/data/'\n",
    "\n",
    "# check if the Spark session is active. If it is activate, close it\n",
    "\n",
    "try:\n",
    "    if spark:\n",
    "        spark.stop()\n",
    "except:\n",
    "    pass    \n",
    "\n",
    "spark = (SparkSession.builder.appName(\"Multidimensional Data Frame\")\n",
    "        .config(\"spark.port.maxRetries\", \"100\")\n",
    "        .config(\"spark.sql.mapKeyDedupPolicy\", \"LAST_WIN\")  # This configuration allow the duplicate keys in the map data type.\n",
    "         .config(\"spark.sql.legacy.timeParserPolicy\", \"LEGACY\")\n",
    "        .config(\"spark.driver.memory\", \"8g\")\n",
    "        .config(\"spark.driver.executor\",\"8g\")\n",
    "        .getOrCreate())\n",
    "\n",
    "# confiture the log level (defaulty is WARN)\n",
    "spark.sparkContext.setLogLevel('ERROR')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7568293f-70a2-4b8c-845c-ca9c3f3c10e1",
   "metadata": {},
   "source": [
    "# Weather data\n",
    "For this exercise, we will use the [National Oceanic and Atmospheric Administration’s (NOAA) Global Surface Summary of the Day (GSOD) data set](https://catalog.data.gov/dataset/global-surface-summary-of-the-day-gsod1). I have downloaed daily Boston weather (Boston Logon weather station 725090) from Google BigQuery. We will focus on weather data in Boston between 2010 and 2024."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11fce21-2dbc-4d16-b403-2514ffe4ad4a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "df=spark.read.csv(data_path+'boston_weather', header=True, inferSchema=True)\n",
    "\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617afd4c-d4ad-493d-b215-c38359fe2769",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f621b335-4b6e-4ee1-83ad-2221cec3ec45",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0647407-6088-4070-842d-4b2a2ad47869",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create a date column based on year, month and day, create another column for year-month\n",
    "\n",
    "df=df.withColumn('date', F.to_date(F.concat_ws('-', df['year'], df['mo'], df['da']), 'yyyy-MM-dd')).orderBy('date')\\\n",
    "     .withColumn('year_month', F.to_date(F.concat_ws('-', df['year'], df['mo']), 'yyyy-MM')).orderBy('date')\n",
    "\n",
    "df.limit(10).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2559f5-4994-4a7e-ab4f-97c89601a460",
   "metadata": {},
   "source": [
    "## Visualize daily temperture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9531b4-07cb-42b5-8bcf-629de3a873d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8000fe9f-ef5d-47b3-a86e-8b266cfed65e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b1d455-f5cd-4239-8209-28ea3fda2bed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d26532-92af-4a5e-89cd-3308346bc61f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1a23f205-73ec-4bce-a1b7-a104200eea24",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Identify the coldest day of each year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0defb26c-7033-4cce-af93-6955cbc024ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.window import Window\n",
    "\n",
    "windowSpec=Window.partitionBy('year')\n",
    "\n",
    "result=df.withColumn('coldestDay', F.min('temp').over(windowSpec))\n",
    "\n",
    "result.where('temp=coldestDay').show()\n",
    "\n",
    "#result.where('temp=coldestDay').drop('coldestDay').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5cb38b9-0703-4bb4-8027-0e8b71b80093",
   "metadata": {},
   "source": [
    "## Identify the hottest day of each year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fda9070-7bfb-42dd-a8ff-7291906bfae5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5a0862e3-b7dc-4d33-a3c7-3d13db6150d6",
   "metadata": {},
   "source": [
    "## Ranking functions\n",
    "\n",
    "This section covers ranking functions: \n",
    "- nonconsecutive ranks with rank()\n",
    "- consecutive ranks with dense_rank()\n",
    "- percentile ranks with percent_rank()\n",
    "- tiles with ntile(), \n",
    "- finally a bare row number with row_number()\n",
    "\n",
    "Ranking functions are used for getting the top (or bottom) record for each window partition, or, more generally, for getting an order according to some column’s value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb59300b-ec14-4459-bfe8-97a52d55bc3c",
   "metadata": {},
   "source": [
    "### Identify the top 3 hottest days per year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37eed37-1820-4c3e-a458-c980856aaaa2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "windowSpec=Window.partitionBy('year').orderBy(F.desc('temp'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ad78a1-a6c2-4e5e-a6b1-9b7e8c8a9698",
   "metadata": {},
   "source": [
    "### Identify the top 5% of the hottest day per year\n",
    "\n",
    "use percent_rank()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70789683-90d2-44d3-8fe4-1262c9c01df2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b32ff977-ba7d-484c-8a93-2bcd6eeb6be2",
   "metadata": {},
   "source": [
    "### Split the temp per year into 10 equal buckets (decile)\n",
    "\n",
    "use ntile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c211e40e-bf29-44a6-b467-bac683a1f2eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e75fa5-9e1e-4e2b-b40e-4611d4f7f25e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# check the temp in decile 1 (10% of the coldest temperature in each year)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb5a524-3c77-4ad1-bae8-691ca87730f2",
   "metadata": {},
   "source": [
    "### Add a row number to your data frame, ignore tie\n",
    "\n",
    "use row_number()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52cdb2e5-3d38-461a-b7e6-f2c71e055718",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "windowSpec=Window.partitionBy('year').orderBy('temp')\n",
    "\n",
    "df.withColumn('row_number', F.row_number().over(windowSpec)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9728e28c-8bc1-404e-bff9-f3d947211c39",
   "metadata": {},
   "source": [
    "## Access the records before or after using lag() and lead()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f823a4bb-3fa3-4770-9fd7-c7086a5b4dbe",
   "metadata": {},
   "source": [
    "### Display average daily temp change by month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bdd10e5-c7da-4753-8214-c9293a0e9a20",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aae7dad-47c1-471c-9385-c89e396434c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a2fc65-b442-492a-b3ac-81218e16feb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2be47b9-8d3f-459f-9892-0b01ab6b7f07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "13557a8e-770d-4947-8a44-4d0447b58886",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Visualize the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd36d9f-39cd-445e-82f8-499261a08187",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01701816-9b37-4e1d-9958-f693a0126597",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e315051-08b4-49cf-a7fe-8591a2335cd0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804af6a1-79b9-4df9-ac5a-19bc4eacb9be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e49dc031-c573-439a-82d3-65df51d28141",
   "metadata": {},
   "source": [
    "#### Display avg, max and min temp change by month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b7233b-5574-4f7c-ae81-3728b90d50fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c44b451-028f-43ce-800f-9b09089f7010",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "08735917-1e0b-4bee-bcf8-a3877ce3cfa2",
   "metadata": {},
   "source": [
    "#### Visualize the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10cf892d-e228-4ccc-bf67-ba5f0a1833f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65cff27-3ed0-4a10-8da3-068766ae2d69",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5539aa93-a041-4cdb-8207-d22791b87483",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35de0942-bca1-4731-8a1d-53201ccd1030",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1a227580-5d8c-4871-ab4b-7ee88f116ddc",
   "metadata": {},
   "source": [
    "## Spark also provides the rowsBetween() and rangeBetween() methods to create window frame boundaries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7177adf-6116-44c0-b2aa-dc2f0a55db43",
   "metadata": {},
   "source": [
    "### Display three days moving average temp for each month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e809ba3e-fb84-4795-ad92-33f727b8cf16",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "windowSpec=Window.partitionBy('year', 'mo').orderBy('da').rowsBetween(-2,0)\n",
    "\n",
    "df1=df.withColumn('3_day_moving_avg', F.avg('temp').over(windowSpec))\n",
    "\n",
    "df1.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b590c80-604c-412d-a4a6-aabbf60c76e6",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "- Window functions are functions that are applied over a portion of a data frame called a window frame. They can perform aggregation, ranking, or analytical operations. A window function will return the data frame with the same number of records, unlike its siblings the groupby-aggregate operation and the group map UDF.\n",
    "- A window frame is defined through a window spec. A window spec mandates how the data frame is split (partitionBy()), how it’s ordered (orderBy()), and how it’s portioned (rowsBetween()/rangeBetween()).\n",
    "- By default, an unordered window frame will be unbounded, meaning that the window frame will be equal to the window partition for every record. An ordered window frame will grow to the left, meaning that each record will have a window frame ranging from the first record in the window partition to the current record.\n",
    "- A window can be bounded by row, meaning that the records included in the window frame are tied to the row boundaries passed as parameters (with the range boundaries added to the row number of the current row), or by range, meaning that the records included in the window frame depend on the value of the current row (with the range boundaries added to the value)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Big Data Analytics",
   "language": "python",
   "name": "bigdataanalytics"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "toc-autonumbering": true,
  "toc-showcode": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
